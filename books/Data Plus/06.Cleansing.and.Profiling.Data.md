# Cleansing and Profiling Data

- Process of working with data to begin to discern information and trends in that data

## Data Profiling Steps

1. Identify and document source data
2. Identify the field names and data types
3. Determine fields to be identified for reporting
4. Check for primary, natural, and foreign keys
5. Recognize all the data in the dataset

## Data Profiling Tools

- Allow both manual techniques and advanced software to start data profiling
    - Power Query in Excel
	- Power BI
	- Tableau
	
## Redundant and Duplicated Data

- Redundant Data, stored in more than one place (table)
    - Work on consolidating data to minimize redundancy
- Duplicated Data, data repeated within the same dataset

## Unnecessary Data

- We don't always need all the data for our analysis
- Only record data that's needed to answer business questions
- Extra data slows down the data systems
- Can be referred to as noise

## Missing Data

- When a field contains, N/A, Null, or is just an empty field
    1. When the value is not applicable to the field
	2. When the dataset doesn't have that information
	3. When the datasets do not match the expected information
	4. When survey data is incomplete
- Filter out NULL values OR replace the Null values

## Invalid Data

- Any data that is incorrect due to:
    - Hard coded data that hasn't been updated
	- Invalid data questions
	- Extreme values and outliers
	- Just plain wrong data
	- Invisible and non-printable characters
- Look for leading and trailing spaces
- Remove/replace invalid data

## Meeting Specifications

- Certain types of quality standards set by database engineers when designing system must be met
- Most common reason that data doesn't meet specifications is wrong data type
- Another reason, improper storage of numeric characters
    - Make sure data conversions are happening during import
	
## Data Outliers

- Any data that is far outside the normal distance of other values in the sample
- Nonparametric Statistics, identifies data not assumed to come from a prescribed model that are predetermined by a small number of parameters
- Parametric, based on assumptions about the distribution of data, example is Student's t-tests
- Non-parametric, not based on assumptions, example is Wilcoxon test



