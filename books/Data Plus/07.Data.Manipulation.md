# Data Manipulation

- Process of recording data so it can better for processing, correlation, analysis, and reporting

## Recoding Data

- Transforming data from one form to another
- Numerical, may transform age 16 to '10 - 20' category
- Categorical, may need to standardize data coming in from surveys, like "Fart County" to just plain "Fart"
- Have option to replace original data or create a new column

## Derived Variables

- Taking existing fields and creating a variable or data point, like when creating a new column to record difference in days between start and end dates
- Optimize for Speed, store derived variables instead of recomputing them each time
- Optimize for Space, store the formula used to calculate new variables

## Value Imputation

- Estimating values
- Substitutes missing values with an educated, best guess, estimate
    - Taking an average of existing values and filling it in
- Need to be careful and transparent on methods used

## Aggregation and Reduction

- Aggregated data, combining data by a group, like census data by zip code, can make the data easier to work with
- Sampling, reduces data size by randomly selecting samples from the original, larger dataset
    - Do it in a way that does not introduce bias
	- Simple, just randomly selecting values
	- Stratified, creating subcategories and randomly selecting from those
	
## Data Masking

- Hides personal or sensitive data, like credit card or SSN numbers
- Either not show the data or mask it with an index field
- Index Field, a unique-nonpersonally identifiable number that can be used as a unique identifier

## Transposing Data

- Converting pivoted data from a wide, easy-to-read format back into its original rows
- Sometimes called unpivoting data

## Appending Data

- Combining data from one dataset to another
- Inline Append, combines data sets together
    - discards original data set
- Intermediate Append, retains individual data sets and creates a new data set with combined data
    - keeps original data

